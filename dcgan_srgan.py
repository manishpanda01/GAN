# -*- coding: utf-8 -*-
"""dcgan-keras-alzheimer-images (2) (2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1H4CqFxKAK-MUdUAFKz73aKCzrjq7ll0L

# Deep Convolutional Generative Adversarial Network(DCGAN)

## Import the necessary libraries
"""

import sys, os, glob, time, imageio
import numpy as np, pandas as pd

import matplotlib.pyplot as plt
import matplotlib.animation as animation
from IPython.display import HTML

from PIL import Image

import torch
import torchvision.utils as vutils
import torchvision.transforms as transforms

from keras import models, layers, optimizers
from keras.models import Sequential
from keras.preprocessing.image import array_to_img, img_to_array, load_img

import tensorflow as tf

"""## Cheik the versions"""

# Python version
print('Python version: {}'.format(sys.version))

# numpy
print('numpy version: {}'.format(np.__version__))

# pandas
print('pandas version: {}'.format(pd.__version__))

# matplotlib
import matplotlib; print('matplotlib version: {}'.format(matplotlib.__version__))

# torch
print('torch version: {}'.format(torch.__version__))

# scikit-learn
import sklearn; print('sklearn version: {}'.format(sklearn.__version__))

# tensorflow
print('tensorflow version: {}'.format(tf.__version__))

"""## Paths and lengths"""

# Define the path to the dataset
dataset_path = '/kaggle/input/mni-alzheimer-data/process_data/'

# List the subdirectories
subdirs = os.listdir(dataset_path)
print("Subdirectories:", subdirs)

# Check the number of images in each subdirectory
for subdir in subdirs:
    subdir_path = os.path.join(dataset_path, subdir)
    print(f"Number of images in {subdir}: {len(os.listdir(subdir_path))}")

from skimage.io import imread
from skimage.transform import resize
# Function to load and preprocess images
def load_images_from_folder(folder, img_size=(128, 128)):
    images = []
    for filename in os.listdir(folder):
        img = imread(os.path.join(folder, filename))
        if img is not None:
            img = resize(img, img_size)
            images.append(img)
    return np.array(images)

# Visualize some images from each subdirectory
img_size = (128, 128)  # Resize images for visualization
fig, axes = plt.subplots(1, len(subdirs), figsize=(20, 5))

for i, subdir in enumerate(subdirs):
    subdir_path = os.path.join(dataset_path, subdir)
    images = load_images_from_folder(subdir_path, img_size)
    axes[i].imshow(images[0])
    axes[i].set_title(subdir)
    axes[i].axis('off')

plt.show()

# Function to load and preprocess all images
def load_all_images_with_labels(dataset_path, img_size=(128, 128)):
    data = []
    labels = []
    subdir_names = os.listdir(dataset_path)
    label_map = {subdir: i for i, subdir in enumerate(subdir_names)}
    reverse_label_map = {i: subdir for subdir, i in label_map.items()}

    for subdir in subdir_names:
        subdir_path = os.path.join(dataset_path, subdir)
        images = load_images_from_folder(subdir_path, img_size)
        data.append(images)
        labels.extend([label_map[subdir]] * len(images))

    data = np.vstack(data)
    labels = np.array(labels)
    return data, labels, reverse_label_map

# Load and preprocess all images
data, labels, reverse_label_map = load_all_images_with_labels(dataset_path, img_size)

# Check the shapes of the data and labels
print("Data shape:", data.shape)
print("Labels shape:", labels.shape)

import seaborn as sns
# Display the distribution of labels with subdirectory names
unique, counts = np.unique(labels, return_counts=True)
label_distribution = {reverse_label_map[label]: count for label, count in zip(unique, counts)}

print("Label distribution:")
for label, count in label_distribution.items():
    print(f"{label}: {count} images")

# Plot the label distribution with subdirectory names
plt.figure(figsize=(12, 6))

# Bar plot
plt.subplot(1, 2, 1)
plt.bar(label_distribution.keys(), label_distribution.values(), color='skyblue')
plt.xlabel('Label')
plt.ylabel('Count')
plt.title('Label Distribution (Count)')
plt.xticks(rotation=45)

# Pie chart
plt.subplot(1, 2, 2)
plt.pie(label_distribution.values(), labels=label_distribution.keys(), autopct='%1.1f%%', startangle=140, colors=sns.color_palette("pastel"))
plt.title('Label Distribution (Pie)')

plt.show()

import numpy as np
from PIL import Image
import os
import time

def get_data_from_dirs(root_path, subdirs, dim=(128, 128), rand_shuffle=True):
    start = time.time()
    imgs_data = []

    for subdir in subdirs:
        subdir_path = os.path.join(root_path, subdir)
        if not os.path.exists(subdir_path):
            print(f"Directory {subdir_path} does not exist.")
            continue

        for img_name in os.listdir(subdir_path):
            img_path = os.path.join(subdir_path, img_name)
            img = Image.open(img_path).convert('RGB').resize(dim, Image.ANTIALIAS)  # Convert to RGB
            img_array = np.array(img)

            imgs_data.append(img_array)

    imgs_data = np.array(imgs_data).astype('float32') / 255.0  # Normalize to [0, 1]

    if rand_shuffle:
        np.random.shuffle(imgs_data)

    print(f"Data loading completed in {time.time() - start:.2f} seconds.")
    return imgs_data

# Define root path and subdirectories
path_root = '/kaggle/input/mni-alzheimer-data/process_data/'
subdirs = ['LMCI', 'EMCI', 'MCI', 'AD', 'CN']

# Load data
data_images = get_data_from_dirs(path_root, subdirs)
print(f"Total images loaded: {data_images.shape[0]}")

"""## Compute the time"""

# Time
def _time(start, end):
    # if in seconds
    if (end-start)<60:
        wall_time = f'{round((end-start),2)}sec'
    # if in minute(s)
    elif (end-start)>=3600:
        wall_time = f'{int((end-start)/3600)}h {int(((end-start)%3600)/60)}min {round((end-start)%60,2)}sec'
    # if in houre(s)
    else:
        wall_time = f'{int((end-start)/60)}min {round((end-start)%60,2)}sec'
    return wall_time

"""## Take a quick look at of the images"""

import matplotlib.pyplot as plt
import numpy as np

def display_images(image_arrays, nrows=4, ncols=5, image_size=(128, 128)):
    plt.figure(figsize=(16, 10))

    # Ensure the number of images doesn't exceed nrows * ncols
    num_images = min(nrows * ncols, len(image_arrays))

    for idx in range(num_images):
        plt.subplot(nrows, ncols, idx + 1)
        img = image_arrays[idx]

        # Resize if necessary
        if img.shape[:2] != image_size:
            img = np.array(Image.fromarray(img).resize(image_size, Image.ANTIALIAS))

        plt.imshow(img)
        plt.axis('off')

    plt.show()

# Example usage:
# Assuming image_arrays is a list or array of image arrays
display_images(data_images)

"""## Get data"""

def define_grid(data_images, nrows=4, ncols=5, plot_grid=True):
    # Save the start time
    start = time.time()

    # Determine the number of images to include in the grid
    num_images = min(nrows * ncols, data_images.shape[0])
    data_images = data_images[:num_images]

    # Initialize the grid with zeros (assuming images are 128x128)
    grid_height = nrows * data_images.shape[1]
    grid_width = ncols * data_images.shape[2]
    grid_channels = data_images.shape[3]
    grid_images = np.zeros((grid_height, grid_width, grid_channels))

    for idx, img in enumerate(data_images):
        row = idx // ncols
        col = idx % ncols
        grid_images[row * 128:(row + 1) * 128, col * 128:(col + 1) * 128] = img

    print(f'The grid was created in {time.time() - start:.2f} seconds')

    # Show the output grid
    if plot_grid:
        plt.figure(figsize=(12, 12))
        plt.axis("off")
        plt.title(f'Grid of {nrows * ncols} images', fontsize=27)
        if grid_channels == 1:
            plt.imshow(grid_images[:, :, 0], cmap='gray')
        else:
            plt.imshow(grid_images)
        plt.show()

    return grid_images

# Define root path and subdirectories
path_root = '/kaggle/input/mni-alzheimer-data/process_data/'
subdirs = ['LMCI', 'EMCI', 'MCI', 'AD', 'CN']

# Load data
data_images = get_data_from_dirs(path_root, subdirs)
print(f"Total images loaded: {data_images.shape[0]}")

# Define the grid and display images
grid_images = define_grid(data_images, nrows=4, ncols=5, plot_grid=True)

# Display the size and shape of the images
print(f"Total number of images loaded: {data_images.shape[0]}")
print(f"Shape of the images: {data_images.shape[1:]}")  # Shape of a single image

"""## Set the parameters  """

# Hyperparameters
n_epoch = 500
batch_size = 64
latent_dim = 100
cols, rows = 128, 128
channels = 3
dim = (cols, rows)
in_shape = (cols, rows, channels)
lr = 0.0002
beta1 = 0.5
nrows, ncols = 3, 4

"""# Discriminator"""

from tensorflow.keras import models, layers, optimizers

def define_discriminator(in_shape=(128,128,3)):
    model = models.Sequential()
    model.add(layers.Conv2D(128, (5,5), padding='same', input_shape=in_shape))
    model.add(layers.LeakyReLU(alpha=0.2))
    model.add(layers.Conv2D(128, (5,5), strides=(2,2), padding='same'))
    model.add(layers.LeakyReLU(alpha=0.2))
    model.add(layers.Conv2D(128, (5,5), strides=(2,2), padding='same'))
    model.add(layers.LeakyReLU(alpha=0.2))
    model.add(layers.Conv2D(128, (5,5), strides=(2,2), padding='same'))
    model.add(layers.LeakyReLU(alpha=0.2))
    model.add(layers.Conv2D(128, (5,5), strides=(2,2), padding='same'))
    model.add(layers.LeakyReLU(alpha=0.2))
    model.add(layers.Flatten())
    model.add(layers.Dropout(0.4))
    model.add(layers.Dense(1, activation='sigmoid'))
    opt = optimizers.Adam(learning_rate=0.0002, beta_1=0.5)
    model.compile(loss='binary_crossentropy', optimizer=opt, metrics=['mse'])
    return model

"""## Generator"""

def define_generator(latent_dim):
    model = models.Sequential()
    n_nodes = 128*8*8
    model.add(layers.Dense(n_nodes, input_dim=latent_dim))
    model.add(layers.LeakyReLU(alpha=0.2))
    model.add(layers.Reshape((8, 8, 128)))
    model.add(layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))
    model.add(layers.LeakyReLU(alpha=0.2))
    model.add(layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))
    model.add(layers.LeakyReLU(alpha=0.2))
    model.add(layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))
    model.add(layers.LeakyReLU(alpha=0.2))
    model.add(layers.Conv2DTranspose(128, (4,4), strides=(2,2), padding='same'))
    model.add(layers.LeakyReLU(alpha=0.2))
    model.add(layers.Conv2D(3, (5,5), activation='tanh', padding='same'))
    return model

# Generate Latent Points
def generate_latent_points(latent_dim, n_samples):
    x_input = np.random.randn(latent_dim * n_samples)
    x_input = x_input.reshape(n_samples, latent_dim)
    return x_input

# Generate Fake Samples
def generate_fake_samples(g_model, latent_dim, n_samples):
    x_input = generate_latent_points(latent_dim, n_samples)
    X = g_model.predict(x_input)
    y = np.zeros((n_samples, 1))
    return X, y

"""## Define GAN model"""

def define_gan(g_model, d_model):
    # Make the discriminator's weights non-trainable
    d_model.trainable = False

    # Define the GAN model
    model = models.Sequential()
    model.add(g_model)  # Add generator
    model.add(d_model)  # Add discriminator

    # Compile the GAN model
    opt = optimizers.Adam(learning_rate=0.0002, beta_1=0.5)
    model.compile(loss='binary_crossentropy', optimizer=opt)
    return model


# Retrieve Real Samples
def get_real_samples(dataset, n_samples):
    ix = np.random.randint(0, dataset.shape[0], n_samples)
    X = dataset[ix]
    y = np.ones((n_samples, 1))
    return X, y

# Save Plot of Generated Images
def show_generated(generated, epoch, nrows=4, ncols=5):
    plt.figure(figsize=(10,10))
    for idx in range(nrows * ncols):
        plt.subplot(nrows, ncols, idx + 1)
        plt.imshow((generated[idx] + 1) / 2)
        plt.axis('off')
    plt.savefig(f'image_at_epoch_{epoch + 1:04d}.png')
    plt.show()

# Evaluate the Discriminator and Plot Generated Images
def summarize_performance(epoch, g_model, d_model, dataset, latent_dim, n_samples=100):
    X_real, y_real = get_real_samples(dataset, n_samples)
    _, acc_real = d_model.evaluate(X_real, y_real, verbose=0)
    x_fake, y_fake = generate_fake_samples(g_model, latent_dim, n_samples)
    _, acc_fake = d_model.evaluate(x_fake, y_fake, verbose=0)
    print(f'> Accuracy at epoch {epoch + 1} [real: {acc_real * 100:.0f}%, fake: {acc_fake * 100:.0f}%]')
    show_generated(x_fake, epoch)

# Plot Loss
def plot_loss(loss):
    plt.figure(figsize=(10,5))
    plt.title("Generator and Discriminator Loss During Training", fontsize=20)
    plt.plot(loss[0], label="D_real")
    plt.plot(loss[1], label="D_fake")
    plt.plot(loss[2], label="G")
    plt.xlabel("Iteration", fontsize=20)
    plt.ylabel("Loss", fontsize=20)
    plt.legend()
    plt.show()

# Time Formatting Function
def _time(start, end):
    hours, rem = divmod(end - start, 3600)
    minutes, seconds = divmod(rem, 60)
    return "{:0>2}:{:0>2}:{:05.2f}".format(int(hours), int(minutes), seconds)

"""# Train the models"""

def train(g_model, d_model, gan_model, dataset, latent_dim=100, n_epochs=500, n_batch=128):
    start = time.time()
    bat_per_epo = int(dataset.shape[0] / n_batch)
    half_batch = int(n_batch / 2)
    loss1, loss2, loss3 = [], [], []

    print('Training Start...')
    for i in range(n_epochs):
        start1 = time.time()
        for j in range(bat_per_epo):
            X_real, y_real = get_real_samples(dataset, half_batch)
            d_loss1, _ = d_model.train_on_batch(X_real, y_real)
            X_fake, y_fake = generate_fake_samples(g_model, latent_dim, half_batch)
            d_loss2, _ = d_model.train_on_batch(X_fake, y_fake)
            X_gan = generate_latent_points(latent_dim, n_batch)
            y_gan = np.ones((n_batch, 1))
            g_loss = gan_model.train_on_batch(X_gan, y_gan)
            loss1.append(d_loss1)
            loss2.append(d_loss2)
            loss3.append(g_loss)

        print(f'Epoch: {i+1}/{n_epochs}, Loss: [D_real = {d_loss1:.3f}, D_fake = {d_loss2:.3f}, G = {g_loss:.3f}], time: {time.time() - start1:.2f} sec')

        if (i+1) % (n_epochs // 10) == 0:
            summarize_performance(i, g_model, d_model, dataset, latent_dim)

    print(f'Total time for training {n_epochs} epochs is {time.time() - start:.2f} sec')
    plot_loss((loss1, loss2, loss3))

# Initialize models
discriminator = define_discriminator()
generator = define_generator(latent_dim)
gan = define_gan(generator, discriminator)

discriminator.summary()

generator.summary()

gan.summary()

# train model
history = train(generator, discriminator, gan, data_images, latent_dim, n_epochs=n_epoch, n_batch=batch_size)

import matplotlib.pyplot as plt
import numpy as np

def plot_generated_images(generator, latent_dim, n_samples=10, grid_size=None):
    # Generate images
    noise = np.random.randn(n_samples, latent_dim)
    generated_images = generator.predict(noise)

    # Scale images to [0, 1]
    generated_images = (generated_images + 1) / 2.0

    # Determine grid size
    if grid_size is None:
        grid_size = int(np.ceil(np.sqrt(n_samples)))

    fig, axes = plt.subplots(grid_size, grid_size, figsize=(grid_size * 2, grid_size * 2))
    axes = axes.flatten()

    for i in range(grid_size * grid_size):
        if i < n_samples:
            axes[i].imshow(generated_images[i])
        axes[i].axis('off')

    plt.tight_layout()
    plt.show()

# Plot some generated images in a grid
plot_generated_images(generator, latent_dim=100, n_samples=50)

from skimage.metrics import structural_similarity as ssim
import numpy as np
def calculate_ssim_mse(real_images, fake_images):
    ssim_scores = []
    mse_scores = []

    for real_img, fake_img in zip(real_images, fake_images):
        # Convert images to grayscale if they are not already
        if len(real_img.shape) == 3 and real_img.shape[2] == 3:
            real_img = np.mean(real_img, axis=-1)
            fake_img = np.mean(fake_img, axis=-1)

        # Compute SSIM and MSE
        ssim_score, _ = ssim(real_img, fake_img, full=True)
        mse_score = np.mean((real_img - fake_img) ** 2)

        ssim_scores.append(ssim_score)
        mse_scores.append(mse_score)

    return np.mean(ssim_scores), np.mean(mse_scores)

def evaluate_discriminator(d_model, generator, dataset, latent_dim, n_samples=100):
    X_real, y_real = get_real_samples(dataset, n_samples)
    X_fake, y_fake = generate_fake_samples(generator, latent_dim, n_samples)

    d_loss_real, _ = d_model.evaluate(X_real, y_real, verbose=0)
    d_loss_fake, _ = d_model.evaluate(X_fake, y_fake, verbose=0)

    print(f'Discriminator Loss on Real Images: {d_loss_real:.3f}')
    print(f'Discriminator Loss on Fake Images: {d_loss_fake:.3f}')

    # Calculate SSIM and MSE
    ssim_score, mse_score = calculate_ssim_mse(X_real, X_fake)
    print(f'Mean SSIM: {ssim_score:.3f}')
    print(f'Mean MSE: {mse_score:.3f}')

# Evaluate the discriminator
evaluate_discriminator(discriminator, generator, data_images, latent_dim=100, n_samples=100)

"""# **SRGAN**"""

import numpy as np
import tensorflow as tf
from tensorflow.keras.layers import Input, Conv2D, Add, LeakyReLU, BatchNormalization, UpSampling2D, Flatten, Concatenate, Dense, Reshape
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam
import matplotlib.pyplot as plt

from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, LeakyReLU, Add

def residual_block(x_in):
    x = Conv2D(64, kernel_size=3, padding='same')(x_in)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)

    x = Conv2D(64, kernel_size=3, padding='same')(x)
    x = BatchNormalization()(x)

    x = Add()([x, x_in])
    return x

from tensorflow.keras.layers import Dense, Reshape, UpSampling2D, Conv2D, BatchNormalization, LeakyReLU
from tensorflow.keras.models import Model

def build_generator(latent_dim=100):
    inputs = Input(shape=(latent_dim,))
    x = Dense(16 * 16 * 128)(inputs)  # Adjust to match your architecture
    x = LeakyReLU(alpha=0.2)(x)
    x = Reshape((16, 16, 128))(x)  # Make sure this matches the dimensions

    x = UpSampling2D()(x)
    x = Conv2D(128, kernel_size=3, padding='same')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)

    x = UpSampling2D()(x)
    x = Conv2D(64, kernel_size=3, padding='same')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)

    x = UpSampling2D()(x)
    x = Conv2D(32, kernel_size=3, padding='same')(x)
    x = BatchNormalization()(x)
    x = LeakyReLU(alpha=0.2)(x)

    x = Conv2D(3, kernel_size=3, padding='same', activation='tanh')(x)

    model = Model(inputs, x)
    return model

from tensorflow.keras.layers import Flatten, Dense
from tensorflow.keras.models import Model
from tensorflow.keras.optimizers import Adam

def build_discriminator(input_shape=(128, 128, 3)):
    inputs = Input(shape=input_shape)
    x = Conv2D(64, kernel_size=3, padding='same')(inputs)
    x = LeakyReLU(alpha=0.2)(x)
    x = Conv2D(128, kernel_size=3, padding='same')(x)
    x = LeakyReLU(alpha=0.2)(x)
    x = Flatten()(x)
    x = Dense(1, activation='sigmoid')(x)  # Output a single probability

    model = Model(inputs, x)
    model.compile(loss='binary_crossentropy', optimizer=Adam())
    return model

from tensorflow.keras.models import Sequential

def build_gan(generator, discriminator):
    discriminator.trainable = False
    gan = Sequential()
    gan.add(generator)
    gan.add(discriminator)
    gan.compile(optimizer=Adam(), loss='binary_crossentropy')
    return gan

from tensorflow.keras.applications import VGG19
from tensorflow.keras.models import Model
import tensorflow as tf

def build_vgg19():
    vgg19 = VGG19(include_top=False, weights='imagenet', input_shape=(128, 128, 3))
    model = Model(inputs=vgg19.input, outputs=vgg19.get_layer('block5_conv4').output)
    model.trainable = False
    return model

def perceptual_loss(y_true, y_pred):
    vgg19 = build_vgg19()
    y_true_features = vgg19(y_true)
    y_pred_features = vgg19(y_pred)
    return tf.reduce_mean(tf.square(y_true_features - y_pred_features))

from IPython.display import Image, display
def save_and_display_generated_images(epoch, generator, latent_dim=100, examples=10, dim=(1, 10), figsize=(10, 1)):
    noise = np.random.randn(examples, latent_dim)
    generated_images = generator.predict(noise)
    generated_images = (generated_images + 1) / 2.0  # Rescale to [0, 1]

    plt.figure(figsize=figsize)
    for i in range(examples):
        plt.subplot(dim[0], dim[1], i + 1)
        plt.imshow(generated_images[i])
        plt.axis('off')
    plt.tight_layout()
    file_name = f'gan_generated_image_epoch_{epoch}.png'
    plt.savefig(file_name)
    plt.close()

    display(Image(filename=file_name))

import numpy as np
from skimage.metrics import structural_similarity as ssim
import tensorflow as tf

def train_sgan(generator, discriminator, gan, dataset, epochs=100, batch_size=64, latent_dim=100, save_interval=10):
    d_losses = []
    g_losses = []
    mse_losses = []
    ssim_losses = []
    for epoch in range(epochs):
        idx = np.random.randint(0, dataset.shape[0], batch_size)
        real_imgs = dataset[idx]
        real_labels = np.ones((batch_size, 1))  # Correct shape for real images

        # Generate fake samples
        noise = np.random.randn(batch_size, latent_dim)  # Ensure this matches the generator input shape
        fake_imgs = generator.predict(noise)
        fake_labels = np.zeros((batch_size, 1))  # Correct shape for fake images

        # Train Discriminator
        d_loss_real = discriminator.train_on_batch(real_imgs, real_labels)
        d_loss_fake = discriminator.train_on_batch(fake_imgs, fake_labels)
        d_loss = (d_loss_real + d_loss_fake) / 2

        # Train Generator
        noise = np.random.randn(batch_size, latent_dim)  # Ensure this matches the generator input shape
        g_loss = gan.train_on_batch(noise, np.ones((batch_size, 1)))  # Use ones for generator

        # Calculate MSE and SSIM
        mse_loss = tf.reduce_mean(tf.square(real_imgs - fake_imgs))
        ssim_score = np.mean([ssim(real_imgs[i], fake_imgs[i], multichannel=True) for i in range(batch_size)])

        d_losses.append(d_loss)
        g_losses.append(g_loss)
        mse_losses.append(mse_loss)
        ssim_losses.append(ssim_score)

        if epoch % 10 == 0:  # Adjusted to show progress more frequently
            print(f'Epoch {epoch}/{epochs} - D Loss: {(d_loss_real + d_loss_fake) / 2:.4f} - G Loss: {g_loss:.4f} - MSE: {mse_loss:.4f} - SSIM: {ssim_score:.4f}')

        # Save and display generated images at specified intervals
        if epoch % save_interval == 0:
            save_and_display_generated_images(epoch, generator, latent_dim)

    return d_losses, g_losses, mse_losses, ssim_losses

# Example usage
latent_dim = 100
img_shape = (128, 128, 3)

generator = build_generator()
discriminator = build_discriminator()
gan = build_gan(generator, discriminator)

generator.summary()

discriminator.summary()

gan.summary()

history2 = train_sgan(generator, discriminator, gan, dataset=data_images, epochs=500, batch_size=32)

import matplotlib.pyplot as plt

def plot_losses(history):
    d_losses, g_losses, mse_losses, ssim_losses = history
    epochs = range(len(d_losses))

    plt.figure(figsize=(12, 8))

    # Plot Discriminator Loss
    plt.plot(epochs, d_losses, label='Discriminator Loss')

    # Plot Generator Loss
    plt.plot(epochs, g_losses, label='Generator Loss')

    # Plot MSE Loss
    plt.plot(epochs, mse_losses, label='MSE Loss')

    # Plot SSIM
    plt.plot(epochs, ssim_losses, label='SSIM')

    plt.xlabel('Epochs')
    plt.ylabel('Value')
    plt.legend()
    plt.title('Training Metrics')
    plt.grid(True)
    plt.tight_layout()
    plt.show()

# Plot the losses and metrics
plot_losses(history2)

import numpy as np
import matplotlib.pyplot as plt

def generate_and_display_images(generator, latent_dim=100, num_images=50, grid_size=(10, 5)):
    # Generate random noise vectors
    noise = np.random.randn(num_images, latent_dim)

    # Generate images from noise
    generated_images = generator.predict(noise)

    # Rescale images from [-1, 1] to [0, 1] for visualization
    generated_images = (generated_images + 1) / 2.0

    # Plot generated images in a grid
    fig, axes = plt.subplots(grid_size[0], grid_size[1], figsize=(20, 10))
    for i in range(grid_size[0]):
        for j in range(grid_size[1]):
            index = i * grid_size[1] + j
            if index < num_images:
                axes[i, j].imshow(generated_images[index])
            axes[i, j].axis('off')

    plt.tight_layout()
    plt.show()

# Generate and display 50 images using the trained generator
generate_and_display_images(generator, latent_dim=100, num_images=50, grid_size=(10, 5))

import numpy as np
import tensorflow as tf

def evaluate_model(generator, dataset, batch_size=32, latent_dim=100):
    idx = np.random.randint(0, dataset.shape[0], batch_size)
    real_imgs = dataset[idx]

    # Normalize images from [0, 255] to [-1, 1] if needed
    real_imgs = (real_imgs - 127.5) / 127.5

    # Generate fake images
    noise = np.random.randn(batch_size, latent_dim)
    fake_imgs = generator.predict(noise)

    # Normalize generated images from [-1, 1] to [0, 1]
    fake_imgs = (fake_imgs + 1) / 2.0

    # Convert to TensorFlow tensors
    real_imgs_tensor = tf.convert_to_tensor(real_imgs, dtype=tf.float32)
    fake_imgs_tensor = tf.convert_to_tensor(fake_imgs, dtype=tf.float32)

    # Calculate MSE Loss
    mse_loss = tf.reduce_mean(tf.keras.losses.MeanSquaredError()(real_imgs_tensor, fake_imgs_tensor)).numpy()

    # Calculate SSIM Loss
    ssim_loss = tf.reduce_mean(tf.image.ssim(real_imgs_tensor, fake_imgs_tensor, max_val=1.0)).numpy()

    print(f'MSE Loss: {mse_loss:.4f} - SSIM: {ssim_loss:.4f}')

    return fake_imgs, mse_loss, ssim_loss

# Example usage
fake_imgs, mse_loss, ssim_loss = evaluate_model(generator, data_images, batch_size=32, latent_dim=100)

